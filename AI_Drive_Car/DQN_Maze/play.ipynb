{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "用 Deep Q Learning 玩迷宫（Maze）游戏\n",
    "\"\"\"\n",
    "\n",
    "from env import Maze\n",
    "from deep_q_learning import DeepQLearning\n",
    "\n",
    "\n",
    "def update():\n",
    "    step = 0  # 控制什么时候学习\n",
    "\n",
    "    for episode in range(300):\n",
    "        # 初始化 state（状态）\n",
    "        state = env.reset()\n",
    "\n",
    "        step_count = 0  # 记录走过的步数\n",
    "\n",
    "        while True:\n",
    "            # 更新可视化环境\n",
    "            env.render()\n",
    "\n",
    "            #  大脑根据 state 挑选 action\n",
    "            action = dqn.choose_action(state)\n",
    "\n",
    "            # 探索者在环境中实施这个 action, 并得到环境返回的下一个 state, reward 和 done (是否是踩到炸弹或者找到宝藏)\n",
    "            state_, reward, done = env.step(action)\n",
    "\n",
    "            step_count += 1  # 增加步数\n",
    "\n",
    "            # DeepQLearning 大脑存储这个过渡（transition） (state, action, reward, state_) 的记忆\n",
    "            dqn.store_transition(state, action, reward, state_)\n",
    "\n",
    "            # 控制学习起始时间和频率 (先积累一定记忆才开始学习)\n",
    "            if (step > 200) and (step % 5 == 0):\n",
    "                dqn.learn()\n",
    "\n",
    "            # 机器人移动到下一个 state\n",
    "            state = state_\n",
    "\n",
    "            # 如果踩到炸弹或者找到宝藏, 这回合就结束了\n",
    "            if done:\n",
    "                print(\"回合 {} 结束. 总步数 : {}\\n\".format(episode + 1, step_count))\n",
    "                break\n",
    "\n",
    "            step += 1  # 总步数\n",
    "\n",
    "    # 结束游戏并关闭窗口\n",
    "    print('游戏结束.\\n')\n",
    "    env.destroy()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建游戏环境\n",
    "    env = Maze()\n",
    "\n",
    "    output_graph_boolean = True  # 是否输出 Tensorboard 日志文件\n",
    "    # 创建 DeepQLearning 对象\n",
    "    dqn = DeepQLearning(env.n_actions, env.n_features,\n",
    "                        learning_rate=0.01,\n",
    "                        discount_factor=0.9,\n",
    "                        e_greedy=0.1,\n",
    "                        replace_target_iter=200,  # 每 200 步替换一次 target_net 的参数\n",
    "                        memory_size=2000,  # 记忆上限\n",
    "                        output_graph=output_graph_boolean\n",
    "                        )\n",
    "\n",
    "    # 开始可视化环境\n",
    "    env.after(100, update)\n",
    "    env.mainloop()\n",
    "\n",
    "    if output_graph_boolean:\n",
    "        print('神经网络的日志文件生成在 logs 文件夹里，请用以下命令在 TensorBoard 中查看网络模型图：')\n",
    "        print('\\ttensorboard --logdir=logs\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
