{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, 第 0 步, 生成器的损失: 0.086, 判别器的损失: 0.674\n",
      "Epoch 0, 第 1 步, 生成器的损失: 0.252, 判别器的损失: 0.656\n",
      "Epoch 0, 第 2 步, 生成器的损失: 0.850, 判别器的损失: 0.539\n",
      "Epoch 0, 第 3 步, 生成器的损失: 1.620, 判别器的损失: 0.446\n",
      "Epoch 0, 第 4 步, 生成器的损失: 1.354, 判别器的损失: 0.529\n",
      "Epoch 0, 第 5 步, 生成器的损失: 2.257, 判别器的损失: 0.365\n",
      "Epoch 0, 第 6 步, 生成器的损失: 3.808, 判别器的损失: 0.342\n",
      "Epoch 0, 第 7 步, 生成器的损失: 2.269, 判别器的损失: 0.539\n",
      "Epoch 0, 第 8 步, 生成器的损失: 2.478, 判别器的损失: 0.438\n",
      "Epoch 0, 第 9 步, 生成器的损失: 3.282, 判别器的损失: 0.414\n",
      "Epoch 0, 第 10 步, 生成器的损失: 3.522, 判别器的损失: 0.482\n",
      "Epoch 0, 第 11 步, 生成器的损失: 2.762, 判别器的损失: 0.528\n",
      "Epoch 0, 第 12 步, 生成器的损失: 2.049, 判别器的损失: 0.552\n",
      "Epoch 0, 第 13 步, 生成器的损失: 1.273, 判别器的损失: 0.715\n",
      "Epoch 0, 第 14 步, 生成器的损失: 0.689, 判别器的损失: 0.750\n",
      "Epoch 0, 第 15 步, 生成器的损失: 0.571, 判别器的损失: 0.599\n",
      "Epoch 0, 第 16 步, 生成器的损失: 0.564, 判别器的损失: 0.526\n",
      "Epoch 0, 第 17 步, 生成器的损失: 0.508, 判别器的损失: 0.508\n",
      "Epoch 0, 第 18 步, 生成器的损失: 0.658, 判别器的损失: 0.564\n",
      "Epoch 0, 第 19 步, 生成器的损失: 0.841, 判别器的损失: 0.410\n",
      "Epoch 0, 第 20 步, 生成器的损失: 1.122, 判别器的损失: 0.401\n",
      "Epoch 0, 第 21 步, 生成器的损失: 1.409, 判别器的损失: 0.395\n",
      "Epoch 0, 第 22 步, 生成器的损失: 0.877, 判别器的损失: 0.585\n",
      "Epoch 1, 第 0 步, 生成器的损失: 1.341, 判别器的损失: 0.515\n",
      "Epoch 1, 第 1 步, 生成器的损失: 1.562, 判别器的损失: 0.424\n",
      "Epoch 1, 第 2 步, 生成器的损失: 1.540, 判别器的损失: 0.339\n",
      "Epoch 1, 第 3 步, 生成器的损失: 2.496, 判别器的损失: 0.253\n",
      "Epoch 1, 第 4 步, 生成器的损失: 2.503, 判别器的损失: 0.337\n",
      "Epoch 1, 第 5 步, 生成器的损失: 1.634, 判别器的损失: 0.505\n",
      "Epoch 1, 第 6 步, 生成器的损失: 2.567, 判别器的损失: 0.428\n",
      "Epoch 1, 第 7 步, 生成器的损失: 3.805, 判别器的损失: 0.467\n",
      "Epoch 1, 第 8 步, 生成器的损失: 3.927, 判别器的损失: 0.379\n",
      "Epoch 1, 第 9 步, 生成器的损失: 2.388, 判别器的损失: 0.443\n",
      "Epoch 1, 第 10 步, 生成器的损失: 1.897, 判别器的损失: 0.303\n",
      "Epoch 1, 第 11 步, 生成器的损失: 1.994, 判别器的损失: 0.316\n",
      "Epoch 1, 第 12 步, 生成器的损失: 2.050, 判别器的损失: 0.502\n",
      "Epoch 1, 第 13 步, 生成器的损失: 1.192, 判别器的损失: 0.630\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f65253c9d659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-f65253c9d659>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mrandom_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m# 生成器 生成的图片数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0minput_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#首尾相连，等于append，真实图像后跟生成图像\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1491\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m       return training_arrays.predict_loop(\n\u001b[1;32m-> 1493\u001b[1;33m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2914\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "训练 DCGAN\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob#读取文件\n",
    "import numpy as np\n",
    "from scipy import misc#科学计算库\n",
    "import tensorflow as tf\n",
    "\n",
    "from network import *\n",
    "\n",
    "\n",
    "def train():\n",
    "    # 确保包含所有图片的 images 文件夹在所有 Python 文件的同级目录下\n",
    "    # 当然了，你也可以自定义文件夹名和路径\n",
    "    if not os.path.exists(\"images\"):\n",
    "        raise Exception(\"包含所有图片的 images 文件夹不在此目录下，请添加\")\n",
    "\n",
    "    # 获取训练数据\n",
    "    data = []\n",
    "    for image in glob.glob(\"images/*\"):\n",
    "        image_data = misc.imread(image)  # imread 利用 PIL 来读取图片数据\n",
    "        data.append(image_data)\n",
    "    input_data = np.array(data)\n",
    "\n",
    "    # 将数据标准化成 [-1, 1] 的取值, 这也是 Tanh 激活函数的输出范围\n",
    "    input_data = (input_data.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "    # 构造 生成器 和 判别器\n",
    "    g = generator_model()\n",
    "    d = discriminator_model()\n",
    "\n",
    "    # 构建 生成器 和 判别器 组成的网络模型\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "\n",
    "    # 优化器用 Adam Optimizer\n",
    "    g_optimizer = tf.keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=BETA_1)\n",
    "    d_optimizer = tf.keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=BETA_1)\n",
    "\n",
    "    # 配置 生成器 和 判别器\n",
    "    g.compile(loss=\"binary_crossentropy\", optimizer=g_optimizer)\n",
    "    d_on_g.compile(loss=\"binary_crossentropy\", optimizer=g_optimizer)\n",
    "    d.trainable = True\n",
    "    d.compile(loss=\"binary_crossentropy\", optimizer=d_optimizer)\n",
    "\n",
    "    # 开始训练\n",
    "    for epoch in range(EPOCHS):\n",
    "        for index in range(int(input_data.shape[0] / BATCH_SIZE)):\n",
    "            input_batch = input_data[index * BATCH_SIZE : (index + 1) * BATCH_SIZE]\n",
    "\n",
    "            # 连续型均匀分布的随机数据（噪声）\n",
    "            random_data = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            # 生成器 生成的图片数据\n",
    "            generated_images = g.predict(random_data, verbose=0)\n",
    "\n",
    "            input_batch = np.concatenate((input_batch, generated_images))#首尾相连，等于append，真实图像后跟生成图像\n",
    "            output_batch = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "\n",
    "            # 训练 判别器，让它具备识别不合格生成图片的能力\n",
    "            d_loss = d.train_on_batch(input_batch, output_batch)\n",
    "\n",
    "            # 当训练 生成器 时，让 判别器 不可被训练\n",
    "            d.trainable = False\n",
    "\n",
    "            # 重新生成随机数据。很关键\n",
    "            random_data = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "\n",
    "            # 训练 生成器，并通过不可被训练的 判别器 去判别\n",
    "            g_loss = d_on_g.train_on_batch(random_data, [1] * BATCH_SIZE)\n",
    "\n",
    "            # 恢复 判别器 可被训练\n",
    "            d.trainable = True\n",
    "\n",
    "            # 打印损失\n",
    "            print(\"Epoch {}, 第 {} 步, 生成器的损失: {:.3f}, 判别器的损失: {:.3f}\".format(epoch, index, g_loss, d_loss))\n",
    "\n",
    "        # 保存 生成器 和 判别器 的参数\n",
    "        # 大家也可以设置保存时名称不同（比如后接 epoch 的数字），参数文件就不会被覆盖了\n",
    "        if epoch % 10 == 9:\n",
    "            g.save_weights(\"generator_weight\", True)\n",
    "            d.save_weights(\"discriminator_weight\", True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
