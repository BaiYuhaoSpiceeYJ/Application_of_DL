{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH]\n",
      "                             [--load_file LOAD_FILE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\TH\\AppData\\Roaming\\jupyter\\runtime\\kernel-cd6c0ca7-e3b3-44ed-9bfa-2b36759bfc07.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "测试神经网络模型\n",
    "\n",
    "大家之后可以加上各种的 name_scope（命名空间）\n",
    "用 TensorBoard 来可视化\n",
    "\n",
    "==== 一些术语的概念 ====\n",
    "# Batch size : 批次(样本)数目。一次迭代（Forword 运算（用于得到损失函数）以及 BackPropagation 运算（用于更新神经网络参数））所用的样本数目。Batch size 越大，所需的内存就越大\n",
    "# Iteration : 迭代。每一次迭代更新一次权重（网络参数），每一次权重更新需要 Batch size 个数据进行 Forward 运算，再进行 BP 运算\n",
    "# Epoch : 纪元/时代。所有的训练样本完成一次迭代\n",
    "\n",
    "# 假如 : 训练集有 1000 个样本，Batch_size=10\n",
    "# 那么 : 训练完整个样本集需要： 100 次 Iteration，1 个 Epoch\n",
    "# 但一般我们都不止训练一个 Epoch\n",
    "\n",
    "==== 超参数（Hyper parameter）====\n",
    "init_scale : 权重参数（Weights）的初始取值跨度，一开始取小一些比较利于训练\n",
    "learning_rate : 学习率，训练时初始为 1.0\n",
    "num_layers : LSTM 层的数目（默认是 2）\n",
    "num_steps : LSTM 展开的步（step）数，相当于每个批次输入单词的数目（默认是 35）\n",
    "hidden_size : LSTM 层的神经元数目，也是词向量的维度（默认是 650）\n",
    "max_lr_epoch : 用初始学习率训练的 Epoch 数目（默认是 10）\n",
    "dropout : 在 Dropout 层的留存率（默认是 0.5）\n",
    "lr_decay : 在过了 max_lr_epoch 之后每一个 Epoch 的学习率的衰减率，训练时初始为 0.93。让学习率逐渐衰减是提高训练效率的有效方法\n",
    "batch_size : 批次(样本)数目。一次迭代（Forword 运算（用于得到损失函数）以及 BackPropagation 运算（用于更新神经网络参数））所用的样本数目\n",
    "（batch_size 默认是 20。取比较小的 batch_size 更有利于 Stochastic Gradient Descent（随机梯度下降），防止被困在局部最小值）\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(r'.\\RNN')\n",
    "#sys.path.append(r'.05 network')\n",
    "from utils import *\n",
    "from network import *\n",
    "\n",
    "\n",
    "def test(model_path, test_data, vocab_size, id_to_word):\n",
    "    # 测试的输入\n",
    "    test_input = Input(batch_size=20, num_steps=35, data=test_data)\n",
    "\n",
    "    # 创建测试的模型，基本的超参数需要和训练时用的一致，例如：\n",
    "    # hidden_size，num_steps，num_layers，vocab_size，batch_size 等等\n",
    "    # 因为我们要载入训练时保存的参数的文件，如果超参数不匹配 TensorFlow 会报错\n",
    "    m = Model(test_input, is_training=False, hidden_size=650, vocab_size=vocab_size, num_layers=2)\n",
    "\n",
    "    # 为了用 Saver 来恢复训练时生成的模型的变量\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Coordinator（协调器），用于协调线程的运行\n",
    "        coord = tf.train.Coordinator()\n",
    "        # 启动线程\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        # 当前的状态\n",
    "        # 第二维是 2 是因为测试时指定只有 2 层 LSTM\n",
    "        # 第二维是 2 是因为对每一个 LSTM 单元有两个来自上一单元的输入：\n",
    "        # 一个是 前一时刻 LSTM 的输出 h(t-1)\n",
    "        # 一个是 前一时刻的单元状态 C(t-1)\n",
    "        current_state = np.zeros((2, 2, m.batch_size, m.hidden_size))\n",
    "\n",
    "        # 恢复被训练的模型的变量\n",
    "        saver.restore(sess, model_path)\n",
    "\n",
    "        # 测试 30 个批次\n",
    "        num_acc_batches = 30\n",
    "\n",
    "        # 打印预测单词和实际单词的批次数\n",
    "        check_batch_idx = 25\n",
    "\n",
    "        # 超过 5 个批次才开始累加精度\n",
    "        acc_check_thresh = 5\n",
    "\n",
    "        # 初始精度的和，用于之后算平均精度\n",
    "        accuracy = 0\n",
    "\n",
    "        for batch in range(num_acc_batches):\n",
    "            if batch == check_batch_idx:\n",
    "                true, pred, current_state, acc = sess.run([m.input_obj.targets, m.predict, m.state, m.accuracy], feed_dict={m.init_state: current_state})\n",
    "                pred_words = [id_to_word[x] for x in pred[:m.num_steps]]\n",
    "                true_words = [id_to_word[x] for x in true[0]]\n",
    "                print(\"\\n实际的单词:\")\n",
    "                print(\" \".join(true_words))  # 真实的单词\n",
    "                print(\"预测的单词:\")\n",
    "                print(\" \".join(pred_words))  # 预测的单词\n",
    "            else:\n",
    "                acc, current_state = sess.run([m.accuracy, m.state], feed_dict={m.init_state: current_state})\n",
    "            if batch >= acc_check_thresh:\n",
    "                accuracy += acc\n",
    "\n",
    "        # 打印平均精度\n",
    "        print(\"平均精度: {:.3f}\".format(accuracy / (num_acc_batches - acc_check_thresh)))\n",
    "\n",
    "        # 关闭线程\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if args.data_path:\n",
    "        data_path = args.data_path\n",
    "    if args.load_file:\n",
    "        load_file = args.load_file\n",
    "    train_data, valid_data, test_data, vocab_size, id_to_word = load_data(data_path)\n",
    "\n",
    "    trained_model = save_path + \"/\" + load_file\n",
    "\n",
    "    test(trained_model, test_data, vocab_size, id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
